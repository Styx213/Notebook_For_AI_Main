{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Зависимости\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import BaggingRegressor, BaggingClassifier, RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\nfrom xgboost import XGBRegressor, XGBClassifier\nfrom sklearn import preprocessing\nfrom sklearn.cluster import KMeans\n\nfrom sklearn.metrics import mean_squared_error, f1_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Генерируем уникальный seed\nmy_code = \"Матвеичева Екатерина Дмитриевна\"\nseed_limit = 2 ** 32\nmy_seed = int.from_bytes(my_code.encode(), \"little\") % seed_limit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Читаем данные из файла\nexample_data = pd.read_csv(\"datasets/Fish.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_data.head()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Определим размер валидационной и тестовой выборок\nval_test_size = round(0.2*len(example_data))\nprint(val_test_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создадим обучающую, валидационную и тестовую выборки\nrandom_state = my_seed\ntrain_val, test = train_test_split(example_data, test_size=val_test_size, random_state=random_state)\ntrain, val = train_test_split(train_val, test_size=val_test_size, random_state=random_state)\nprint(len(train), len(val), len(test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Значения в числовых столбцах преобразуем к отрезку [0,1].\n# Для настройки скалировщика используем только обучающую выборку.\nnum_columns = ['Weight', 'Length1', 'Length2', 'Length3', 'Height', 'Width']\n\nct = ColumnTransformer(transformers=[('numerical', MinMaxScaler(), num_columns)], remainder='passthrough')\nct.fit(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Преобразуем значения, тип данных приводим к DataFrame\nsc_train = pd.DataFrame(ct.transform(train))\nsc_test = pd.DataFrame(ct.transform(test))\nsc_val = pd.DataFrame(ct.transform(val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Устанавливаем названия столбцов\ncolumn_names = num_columns + ['Species']\nsc_train.columns = column_names\nsc_test.columns = column_names\nsc_val.columns = column_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Явно укажем типы данных, это важно для xgboost\ntypes = {\n    'Weight' : 'float64',\n    'Length1' : 'float64',\n    'Length2' : 'float64',\n    'Length3' : 'float64',\n    'Height' : 'float64',\n    'Width' : 'float64',\n    'Species' : 'category'\n}\nsc_train = sc_train.astype(types)\nsc_test = sc_test.astype(types)\nsc_val = sc_val.astype(types)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Задание №1 - анализ различных типов ансамблей решений в задаче регрессии\n# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html\n# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n# https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n = 4\nlabels = random.sample(num_columns, n)\n\ny_labels = labels[0]\nx_labels = labels[1:]\n\nprint(x_labels)\nprint(y_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = sc_train[x_labels]\nx_test = sc_test[x_labels]\nx_val = sc_val[x_labels]\n\ny_train = sc_train[y_labels]\ny_test = sc_test[y_labels]\ny_val = sc_val[y_labels]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создайте 4 различных модели с использованием следующих классов:\n# BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor, XGBRegressor.\n# Решите получившуюся задачу регрессии с помощью созданных моделей и сравните их эффективность.\n# Укажите, какая модель решает задачу лучше других.\n\n# mean_squared_error -> min ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r_models=[\nBaggingRegressor(), \n    RandomForestRegressor(),\n    GradientBoostingRegressor(), \n    XGBRegressor()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r_models=[]\n\n#Регрессор Бэгинга\nr_models.append(BaggingRegressor())\n\n#случайный лес\nr_models.append(RandomForestRegressor())\n\n#градиентный бустинг\nr_models.append(GradientBoostingRegressor())\n\n#eXtrem Gradient Boosting\nr_models.append(XGBRegressor())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r_models","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = sc_train[x_labels]\nx_test = sc_test[x_labels]\nx_val = sc_val[x_labels]\n\ny_train = np.ravel(sc_train[y_labels])\ny_test = np.ravel(sc_test[y_labels])\ny_val = np.ravel(sc_val[y_labels])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model in r_models:\n    print(model)\n    model.fit(x_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mses = []\nfor model in r_models:\n    val_pred = model.predict(x_val)\n    mse = mean_squared_error(y_val, val_pred)\n    mses.append(mse)\n    print(model, '\\t', mse)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Выбираем лучшую модель\ni_min = mses.index(min(mses))\nbest_r_model = r_models[i_min]\nbest_r_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred = best_r_model.predict(x_test)\nmse = mean_squared_error(y_test, test_pred)\nprint(mse)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Задание №2 - анализ различных типов ансамблей в задаче классификации\n# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\n# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n# https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Выбираем 2 числовых переменных, которые будут параметрами элементов набора данных\n# Метка класса всегда 'Species'\nn = 2\nx_labels = random.sample(num_columns, n)\ny_label = 'Species'\n\nprint(x_labels)\nprint(y_label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Отберем необходимые параметры\nx_train = sc_train[x_labels]\nx_test = sc_test[x_labels]\nx_val = sc_val[x_labels]\n\ny_train = sc_train[y_label]\ny_test = sc_test[y_label]\ny_val = sc_val[y_label]","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создайте 4 различных модели с использованием следующих классов:\n# BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier, XGBClassifier\n# Решите получившуюся задачу классификации с помощью созданных моделей и сравните их эффективность.\n# Укажите, какая модель решает задачу лучше других.\n\n# f1_score -> max","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = preprocessing.LabelEncoder()\ny_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le.fit(y_train)\nle.fit(y_val)\nle.fit(y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train=le.transform(y_train)\ny_val=le.transform(y_val)\ny_test=le.transform(y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a_models=[\nBaggingClassifier(), \n    RandomForestClassifier(),\n    GradientBoostingClassifier(), \n    XGBClassifier()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a_models=[]\n\n#Регрессор Бэгинга\na_models.append(BaggingClassifier())\n\n#случайный лес\na_models.append(RandomForestClassifier())\n\n#градиентный бустинг\na_models.append(GradientBoostingClassifier())\n\n#eXtrem Gradient Boosting\na_models.append(XGBClassifier(use_label_encoder=False,\n                              eval_metric='mlogloss'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Обучаем модели\nfor model in a_models:\n    print(model)\n    model.fit(x_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Оценииваем качество работы моделей на валидационной выборке.\nf1s = []\nfor model in a_models:\n    val_pred = model.predict(x_val)\n    f1 = f1_score(y_val, val_pred, average='weighted')\n    f1s.append(f1)\n    print(model, '\\t', f1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Выбираем лучшую модель\ni_max = f1s.index(max(f1s))\nbest_a_model = a_models[i_max]\nbest_a_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Вычислим ошибку лучшей модели на тестовой выборке.\ntest_pred = best_a_model.predict(x_test)\nf1 = f1_score(y_test, test_pred, average='weighted')\nprint(f1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}