{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Зависимости\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import BaggingRegressor, BaggingClassifier, RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\nfrom xgboost import XGBRegressor, XGBClassifier\nfrom sklearn import preprocessing\nfrom sklearn.cluster import KMeans\n\nfrom sklearn.metrics import mean_squared_error, f1_score","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Генерируем уникальный seed\nmy_code = \"Maslixin\"\nseed_limit = 2 ** 32\nmy_seed = int.from_bytes(my_code.encode(), \"little\") % seed_limit","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Читаем данные из файла\nexample_data = pd.read_csv(\"datasets/Fish.csv\")","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"example_data.head()","metadata":{"scrolled":true,"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"  Species  Weight  Length1  Length2  Length3   Height   Width\n0   Bream   242.0     23.2     25.4     30.0  11.5200  4.0200\n1   Bream   290.0     24.0     26.3     31.2  12.4800  4.3056\n2   Bream   340.0     23.9     26.5     31.1  12.3778  4.6961\n3   Bream   363.0     26.3     29.0     33.5  12.7300  4.4555\n4   Bream   430.0     26.5     29.0     34.0  12.4440  5.1340","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Species</th>\n      <th>Weight</th>\n      <th>Length1</th>\n      <th>Length2</th>\n      <th>Length3</th>\n      <th>Height</th>\n      <th>Width</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Bream</td>\n      <td>242.0</td>\n      <td>23.2</td>\n      <td>25.4</td>\n      <td>30.0</td>\n      <td>11.5200</td>\n      <td>4.0200</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bream</td>\n      <td>290.0</td>\n      <td>24.0</td>\n      <td>26.3</td>\n      <td>31.2</td>\n      <td>12.4800</td>\n      <td>4.3056</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Bream</td>\n      <td>340.0</td>\n      <td>23.9</td>\n      <td>26.5</td>\n      <td>31.1</td>\n      <td>12.3778</td>\n      <td>4.6961</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bream</td>\n      <td>363.0</td>\n      <td>26.3</td>\n      <td>29.0</td>\n      <td>33.5</td>\n      <td>12.7300</td>\n      <td>4.4555</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Bream</td>\n      <td>430.0</td>\n      <td>26.5</td>\n      <td>29.0</td>\n      <td>34.0</td>\n      <td>12.4440</td>\n      <td>5.1340</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Определим размер валидационной и тестовой выборок\nval_test_size = round(0.2*len(example_data))\nprint(val_test_size)","metadata":{"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"32\n","output_type":"stream"}]},{"cell_type":"code","source":"# Создадим обучающую, валидационную и тестовую выборки\nrandom_state = my_seed\ntrain_val, test = train_test_split(example_data, test_size=val_test_size, random_state=random_state)\ntrain, val = train_test_split(train_val, test_size=val_test_size, random_state=random_state)\nprint(len(train), len(val), len(test))","metadata":{"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"95 32 32\n","output_type":"stream"}]},{"cell_type":"code","source":"train","metadata":{"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"    Species  Weight  Length1  Length2  Length3   Height   Width\n54    Roach   390.0     29.5     31.7     35.0   9.4850  5.3550\n115   Perch   690.0     34.6     37.0     39.3  10.5717  6.3666\n48    Roach   169.0     22.0     24.0     27.2   7.5344  3.8352\n82    Perch   110.0     19.0     21.0     22.5   5.6925  3.5550\n40    Roach     0.0     19.0     20.5     22.8   6.4752  3.3516\n..      ...     ...      ...      ...      ...      ...     ...\n73    Perch    32.0     12.5     13.7     14.7   3.5280  1.9992\n133    Pike   345.0     36.0     38.5     41.0   6.3960  3.9770\n10    Bream   475.0     28.4     31.0     36.2  14.2628  5.1042\n70   Parkki   273.0     23.0     25.0     28.0  11.0880  4.1440\n38    Roach    87.0     18.2     19.8     22.2   5.6166  3.1746\n\n[95 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Species</th>\n      <th>Weight</th>\n      <th>Length1</th>\n      <th>Length2</th>\n      <th>Length3</th>\n      <th>Height</th>\n      <th>Width</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>54</th>\n      <td>Roach</td>\n      <td>390.0</td>\n      <td>29.5</td>\n      <td>31.7</td>\n      <td>35.0</td>\n      <td>9.4850</td>\n      <td>5.3550</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>Perch</td>\n      <td>690.0</td>\n      <td>34.6</td>\n      <td>37.0</td>\n      <td>39.3</td>\n      <td>10.5717</td>\n      <td>6.3666</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>Roach</td>\n      <td>169.0</td>\n      <td>22.0</td>\n      <td>24.0</td>\n      <td>27.2</td>\n      <td>7.5344</td>\n      <td>3.8352</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>Perch</td>\n      <td>110.0</td>\n      <td>19.0</td>\n      <td>21.0</td>\n      <td>22.5</td>\n      <td>5.6925</td>\n      <td>3.5550</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Roach</td>\n      <td>0.0</td>\n      <td>19.0</td>\n      <td>20.5</td>\n      <td>22.8</td>\n      <td>6.4752</td>\n      <td>3.3516</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>Perch</td>\n      <td>32.0</td>\n      <td>12.5</td>\n      <td>13.7</td>\n      <td>14.7</td>\n      <td>3.5280</td>\n      <td>1.9992</td>\n    </tr>\n    <tr>\n      <th>133</th>\n      <td>Pike</td>\n      <td>345.0</td>\n      <td>36.0</td>\n      <td>38.5</td>\n      <td>41.0</td>\n      <td>6.3960</td>\n      <td>3.9770</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Bream</td>\n      <td>475.0</td>\n      <td>28.4</td>\n      <td>31.0</td>\n      <td>36.2</td>\n      <td>14.2628</td>\n      <td>5.1042</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>Parkki</td>\n      <td>273.0</td>\n      <td>23.0</td>\n      <td>25.0</td>\n      <td>28.0</td>\n      <td>11.0880</td>\n      <td>4.1440</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Roach</td>\n      <td>87.0</td>\n      <td>18.2</td>\n      <td>19.8</td>\n      <td>22.2</td>\n      <td>5.6166</td>\n      <td>3.1746</td>\n    </tr>\n  </tbody>\n</table>\n<p>95 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Значения в числовых столбцах преобразуем к отрезку [0,1].\n# Для настройки скалировщика используем только обучающую выборку.\nnum_columns = ['Weight', 'Length1', 'Length2', 'Length3', 'Height', 'Width']\n\nct = ColumnTransformer(transformers=[('numerical', MinMaxScaler(), num_columns)], remainder='passthrough')\nct.fit(train)","metadata":{"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"ColumnTransformer(remainder='passthrough',\n                  transformers=[('numerical', MinMaxScaler(),\n                                 ['Weight', 'Length1', 'Length2', 'Length3',\n                                  'Height', 'Width'])])"},"metadata":{}}]},{"cell_type":"code","source":"# Преобразуем значения, тип данных приводим к DataFrame\nsc_train = pd.DataFrame(ct.transform(train))\nsc_test = pd.DataFrame(ct.transform(test))\nsc_val = pd.DataFrame(ct.transform(val))","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"sc_train","metadata":{"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"           0         1         2         3         4         5       6\n0    0.24375  0.432548  0.436255  0.454887  0.455579  0.607155   Roach\n1    0.43125  0.541756  0.541833  0.535714  0.519406  0.749746   Perch\n2   0.105625  0.271949  0.282869  0.308271  0.341012   0.39293   Roach\n3    0.06875  0.207709  0.223108  0.219925  0.232829  0.353434   Perch\n4        0.0  0.207709  0.213147  0.225564    0.2788  0.324763   Roach\n..       ...       ...       ...       ...       ...       ...     ...\n90      0.02  0.068522  0.077689  0.073308  0.105698  0.134134   Perch\n91  0.215625  0.571734  0.571713  0.567669  0.274149  0.412917    Pike\n92  0.296875  0.408994  0.422311  0.477444    0.7362  0.571803   Bream\n93  0.170625  0.293362  0.302789  0.323308   0.54973  0.436457  Parkki\n94  0.054375  0.190578  0.199203  0.214286  0.228371  0.299814   Roach\n\n[95 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.24375</td>\n      <td>0.432548</td>\n      <td>0.436255</td>\n      <td>0.454887</td>\n      <td>0.455579</td>\n      <td>0.607155</td>\n      <td>Roach</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.43125</td>\n      <td>0.541756</td>\n      <td>0.541833</td>\n      <td>0.535714</td>\n      <td>0.519406</td>\n      <td>0.749746</td>\n      <td>Perch</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.105625</td>\n      <td>0.271949</td>\n      <td>0.282869</td>\n      <td>0.308271</td>\n      <td>0.341012</td>\n      <td>0.39293</td>\n      <td>Roach</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.06875</td>\n      <td>0.207709</td>\n      <td>0.223108</td>\n      <td>0.219925</td>\n      <td>0.232829</td>\n      <td>0.353434</td>\n      <td>Perch</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.207709</td>\n      <td>0.213147</td>\n      <td>0.225564</td>\n      <td>0.2788</td>\n      <td>0.324763</td>\n      <td>Roach</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>0.02</td>\n      <td>0.068522</td>\n      <td>0.077689</td>\n      <td>0.073308</td>\n      <td>0.105698</td>\n      <td>0.134134</td>\n      <td>Perch</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>0.215625</td>\n      <td>0.571734</td>\n      <td>0.571713</td>\n      <td>0.567669</td>\n      <td>0.274149</td>\n      <td>0.412917</td>\n      <td>Pike</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>0.296875</td>\n      <td>0.408994</td>\n      <td>0.422311</td>\n      <td>0.477444</td>\n      <td>0.7362</td>\n      <td>0.571803</td>\n      <td>Bream</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>0.170625</td>\n      <td>0.293362</td>\n      <td>0.302789</td>\n      <td>0.323308</td>\n      <td>0.54973</td>\n      <td>0.436457</td>\n      <td>Parkki</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>0.054375</td>\n      <td>0.190578</td>\n      <td>0.199203</td>\n      <td>0.214286</td>\n      <td>0.228371</td>\n      <td>0.299814</td>\n      <td>Roach</td>\n    </tr>\n  </tbody>\n</table>\n<p>95 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Устанавливаем названия столбцов\ncolumn_names = num_columns + ['Species']\nsc_train.columns = column_names\nsc_test.columns = column_names\nsc_val.columns = column_names","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Явно укажем типы данных, это важно для xgboost\ntypes = {\n    'Weight' : 'float64',\n    'Length1' : 'float64',\n    'Length2' : 'float64',\n    'Length3' : 'float64',\n    'Height' : 'float64',\n    'Width' : 'float64',\n    'Species' : 'category'\n}\nsc_train = sc_train.astype(types)\nsc_test = sc_test.astype(types)\nsc_val = sc_val.astype(types)","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Задание №1 - анализ различных типов ансамблей решений в задаче регрессии\n# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html\n# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n# https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn","metadata":{"tags":[],"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Выбираем 4 числовых переменных, три их них будут предикторами, одна - зависимой переменной\nn = 4\nlabels = random.sample(num_columns, n)\n\ny_label = labels[0]\nx_labels = labels[1:]\n\nprint(x_labels)\nprint(y_label)","metadata":{"scrolled":true,"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"['Length1', 'Weight', 'Height']\nLength2\n","output_type":"stream"}]},{"cell_type":"code","source":"# Отберем необходимые параметры\nx_train = sc_train[x_labels]\nx_test = sc_test[x_labels]\nx_val = sc_val[x_labels]\n\ny_train = sc_train[y_label]\ny_test = sc_test[y_label]\ny_val = sc_val[y_label]","metadata":{"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Создайте 4 различных модели с использованием следующих классов:\n# BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor, XGBRegressor.\n# Решите получившуюся задачу регрессии с помощью созданных моделей и сравните их эффективность.\n# Укажите, какая модель решает задачу лучше других.\n\n# mean_squared_error -> min ","metadata":{"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"r_models=[BaggingRegressor(), RandomForestRegressor(),GradientBoostingRegressor(), XGBRegressor()]\n","metadata":{"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"r_models=[]\n\nr_models.append(BaggingRegressor())\n\nr_models.append(RandomForestRegressor())\n\nr_models.append(GradientBoostingRegressor())\n\nr_models.append(XGBRegressor())\n","metadata":{"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"r_models","metadata":{"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"[BaggingRegressor(),\n RandomForestRegressor(),\n GradientBoostingRegressor(),\n XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n              colsample_bynode=None, colsample_bytree=None,\n              enable_categorical=False, gamma=None, gpu_id=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_delta_step=None, max_depth=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n              predictor=None, random_state=None, reg_alpha=None, reg_lambda=None,\n              scale_pos_weight=None, subsample=None, tree_method=None,\n              validate_parameters=None, verbosity=None)]"},"metadata":{}}]},{"cell_type":"code","source":"x_train = sc_train[x_labels]\nx_test = sc_test[x_labels]\nx_val = sc_val[x_labels]\n\ny_train = np.ravel(sc_train[y_label])\ny_test = np.ravel(sc_test[y_label])\ny_val = np.ravel(sc_val[y_label])\n","metadata":{"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"array([0.43625498, 0.54183267, 0.28286853, 0.22310757, 0.21314741,\n       1.        , 0.30278884, 0.01593625, 0.64143426, 0.33266932,\n       0.20318725, 0.67131474, 0.02390438, 0.35258964, 0.21713147,\n       1.        , 0.26294821, 0.24302789, 0.41633466, 0.27290837,\n       0.48207171, 0.50199203, 0.59163347, 0.32270916, 0.08565737,\n       0.70119522, 0.        , 0.15737052, 0.62151394, 0.33266932,\n       0.16733068, 0.60159363, 0.28286853, 0.20318725, 0.28286853,\n       0.15139442, 0.66135458, 0.6812749 , 0.31075697, 0.76095618,\n       0.32270916, 0.25697211, 0.09760956, 0.0438247 , 0.27091633,\n       0.60159363, 0.44820717, 0.16334661, 0.02788845, 0.17729084,\n       0.32868526, 0.40239044, 0.03984064, 0.25298805, 0.83466135,\n       0.60159363, 0.50199203, 0.18326693, 0.58167331, 0.27290837,\n       0.05179283, 0.40239044, 0.65139442, 0.54183267, 0.52191235,\n       0.42231076, 0.29482072, 0.47211155, 0.58167331, 0.31474104,\n       0.18326693, 0.06374502, 0.12749004, 0.3625498 , 0.24302789,\n       0.25298805, 0.49203187, 0.44223108, 0.40239044, 0.25298805,\n       0.53187251, 0.23306773, 0.49203187, 0.03984064, 0.50199203,\n       0.26294821, 0.58167331, 0.25298805, 0.50199203, 0.50199203,\n       0.07768924, 0.57171315, 0.42231076, 0.30278884, 0.19920319])"},"metadata":{}}]},{"cell_type":"code","source":"for model in r_models:\n    print(model)\n    model.fit(x_train, y_train)","metadata":{"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"BaggingRegressor()\nRandomForestRegressor()\nGradientBoostingRegressor()\nXGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n             colsample_bynode=None, colsample_bytree=None,\n             enable_categorical=False, gamma=None, gpu_id=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=None, max_delta_step=None, max_depth=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, reg_alpha=None, reg_lambda=None,\n             scale_pos_weight=None, subsample=None, tree_method=None,\n             validate_parameters=None, verbosity=None)\n","output_type":"stream"}]},{"cell_type":"code","source":"mses = []\nfor model in r_models:\n    val_pred = model.predict(x_val)\n    mse = mean_squared_error(y_val, val_pred)\n    mses.append(mse)\n    print(model, '\\t', mse)","metadata":{"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"BaggingRegressor() \t 0.00022532876462278342\nRandomForestRegressor() \t 0.00016400889221996414\nGradientBoostingRegressor() \t 0.0002099304248316422\nXGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n             gamma=0, gpu_id=-1, importance_type=None,\n             interaction_constraints='', learning_rate=0.300000012,\n             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n             monotone_constraints='()', n_estimators=100, n_jobs=4,\n             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n             validate_parameters=1, verbosity=None) \t 0.0003203511809131044\n","output_type":"stream"}]},{"cell_type":"code","source":"i_min = mses.index(min(mses))\nbest_r_model = r_models[i_min]\nbest_r_model","metadata":{"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"RandomForestRegressor()"},"metadata":{}}]},{"cell_type":"code","source":"test_pred = best_r_model.predict(x_test)\nmse = mean_squared_error(y_test, test_pred)\nprint(mse)","metadata":{"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"0.0004495564430524924\n","output_type":"stream"}]},{"cell_type":"code","source":"# Задание №2 - анализ различных типов ансамблей в задаче классификации\n# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\n# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n# https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn","metadata":{"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Выбираем 2 числовых переменных, которые будут параметрами элементов набора данных\n# Метка класса всегда 'Species'\nn = 2\nx_labels = random.sample(num_columns, n)\ny_label = 'Species'\n\nprint(x_labels)\nprint(y_label)","metadata":{"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"['Width', 'Weight']\nSpecies\n","output_type":"stream"}]},{"cell_type":"code","source":"x_train = sc_train[x_labels]\nx_test = sc_test[x_labels]\nx_val = sc_val[x_labels]\n\ny_train = sc_train[y_label]\ny_test = sc_test[y_label]\ny_val = sc_val[y_label]","metadata":{"scrolled":true,"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"x_train","metadata":{"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"       Width    Weight\n0   0.607155  0.243750\n1   0.749746  0.431250\n2   0.392930  0.105625\n3   0.353434  0.068750\n4   0.324763  0.000000\n..       ...       ...\n90  0.134134  0.020000\n91  0.412917  0.215625\n92  0.571803  0.296875\n93  0.436457  0.170625\n94  0.299814  0.054375\n\n[95 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Width</th>\n      <th>Weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.607155</td>\n      <td>0.243750</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.749746</td>\n      <td>0.431250</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.392930</td>\n      <td>0.105625</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.353434</td>\n      <td>0.068750</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.324763</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>0.134134</td>\n      <td>0.020000</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>0.412917</td>\n      <td>0.215625</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>0.571803</td>\n      <td>0.296875</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>0.436457</td>\n      <td>0.170625</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>0.299814</td>\n      <td>0.054375</td>\n    </tr>\n  </tbody>\n</table>\n<p>95 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Создайте 4 различных модели с использованием следующих классов:\n# BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier, XGBClassifier\n# Решите получившуюся задачу классификации с помощью созданных моделей и сравните их эффективность.\n# Укажите, какая модель решает задачу лучше других.\n\n# f1_score -> max","metadata":{"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"le = preprocessing.LabelEncoder()\ny_test","metadata":{"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"0         Perch\n1         Roach\n2         Roach\n3         Roach\n4         Perch\n5        Parkki\n6         Roach\n7         Perch\n8         Perch\n9          Pike\n10    Whitefish\n11        Bream\n12        Perch\n13        Bream\n14         Pike\n15        Bream\n16        Bream\n17         Pike\n18        Perch\n19         Pike\n20        Perch\n21    Whitefish\n22        Bream\n23        Perch\n24        Perch\n25        Perch\n26        Bream\n27        Perch\n28        Bream\n29        Bream\n30        Smelt\n31        Perch\nName: Species, dtype: category\nCategories (7, object): ['Bream', 'Parkki', 'Perch', 'Pike', 'Roach', 'Smelt', 'Whitefish']"},"metadata":{}}]},{"cell_type":"code","source":"le.fit(y_train)\nle.fit(y_val)\nle.fit(y_test)","metadata":{"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"LabelEncoder()"},"metadata":{}}]},{"cell_type":"code","source":"y_train=le.transform(y_train)\ny_val=le.transform(y_val)\ny_test=le.transform(y_test)","metadata":{"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"array([4, 2, 4, 2, 4, 3, 2, 5, 2, 6, 4, 2, 5, 2, 1, 3, 1, 2, 0, 4, 3, 0,\n       0, 1, 4, 3, 5, 1, 0, 2, 4, 2, 2, 1, 2, 2, 3, 2, 0, 3, 6, 2, 1, 5,\n       4, 2, 3, 2, 5, 2, 0, 0, 5, 4, 3, 2, 0, 2, 2, 2, 5, 2, 3, 2, 0, 6,\n       2, 0, 2, 2, 1, 5, 2, 2, 4, 4, 2, 0, 0, 4, 2, 1, 0, 5, 2, 2, 2, 2,\n       0, 3, 2, 3, 0, 1, 4])"},"metadata":{}}]},{"cell_type":"code","source":"a_models=[BaggingClassifier(),     \n          RandomForestClassifier(),    \n          GradientBoostingClassifier(),    \n          XGBClassifier()]\n","metadata":{"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"a_models=[]\n\na_models.append(BaggingClassifier())\n\na_models.append(RandomForestClassifier())\n\na_models.append(GradientBoostingClassifier())\n\na_models.append(XGBClassifier(use_label_encoder=False,\n                              eval_metric='mlogloss'))","metadata":{"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"for model in a_models:\n    print(model)\n    model.fit(x_train, y_train)","metadata":{"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"BaggingClassifier()\nRandomForestClassifier()\nGradientBoostingClassifier()\nXGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n              colsample_bynode=None, colsample_bytree=None,\n              enable_categorical=False, eval_metric='mlogloss', gamma=None,\n              gpu_id=None, importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_delta_step=None, max_depth=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n              predictor=None, random_state=None, reg_alpha=None,\n              reg_lambda=None, scale_pos_weight=None, subsample=None,\n              tree_method=None, use_label_encoder=False,\n              validate_parameters=None, verbosity=None)\n","output_type":"stream"}]},{"cell_type":"code","source":"f1s = []\nfor model in a_models:\n    val_pred = model.predict(x_val)\n    f1 = f1_score(y_val, val_pred, average='weighted')\n    f1s.append(f1)\n    print(model, '\\t', f1)","metadata":{"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"BaggingClassifier() \t 0.6622282608695653\nRandomForestClassifier() \t 0.5372176044330776\nGradientBoostingClassifier() \t 0.5494791666666666\nXGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n              eval_metric='mlogloss', gamma=0, gpu_id=-1, importance_type=None,\n              interaction_constraints='', learning_rate=0.300000012,\n              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n              monotone_constraints='()', n_estimators=100, n_jobs=4,\n              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n              subsample=1, tree_method='exact', use_label_encoder=False,\n              validate_parameters=1, ...) \t 0.5452380952380952\n","output_type":"stream"}]},{"cell_type":"code","source":"i_max = f1s.index(max(f1s))\nbest_a_model = a_models[i_max]\nbest_a_model","metadata":{"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"BaggingClassifier()"},"metadata":{}}]},{"cell_type":"code","source":"test_pred = best_a_model.predict(x_test)\nf1 = f1_score(y_test, test_pred, average='weighted')\nprint(f1)","metadata":{"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"0.4946633825944171\n","output_type":"stream"}]}]}